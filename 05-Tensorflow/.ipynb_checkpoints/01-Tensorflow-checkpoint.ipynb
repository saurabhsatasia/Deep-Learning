{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "trying-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sophisticated-stock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Keras version: 2.2.4-tf\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "portuguese-taylor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "WARNING:tensorflow:From <ipython-input-9-e16782003dfe>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU\n",
      "GPU #0?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "variable = tf.Variable([3, 3])\n",
    "if tf.test.is_gpu_available():\n",
    "    print('GPU')\n",
    "    print('GPU #0?')\n",
    "    print(variable.device.endswith('GPU:0'))\n",
    "else:\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wired-interface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worse-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9964483664649540287\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3135687886\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12906192970671526293\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "first-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Run on the GPU\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-toyota",
   "metadata": {},
   "source": [
    "### Tensor Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intensive-jimmy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "tf_constant = tf.constant(42)\n",
    "print(tf_constant)\n",
    "print(tf_constant.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "listed-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(99, shape=(), dtype=int64)\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "tf_const1 = tf.constant(99, dtype = tf.int64)\n",
    "print(tf_const1)\n",
    "print(tf_const1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "functional-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 2]\n",
      " [9 5]], shape=(2, 2), dtype=int32)\n",
      "[[4 2]\n",
      " [9 5]]\n"
     ]
    }
   ],
   "source": [
    "tf_arr = tf.constant([[4,2],[9,5]])\n",
    "print(tf_arr)\n",
    "print(tf_arr.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-dressing",
   "metadata": {},
   "source": [
    "#### Commonly used method is to generate constant tf.ones and the tf.zeros like of numpy np.ones & np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unlimited-fantasy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(3, 2), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[4 6 8]\n",
      " [4 6 8]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.ones(shape=(2,3)))\n",
    "print(\"-\"*50)\n",
    "print(tf.zeros(shape=(3,2)))\n",
    "print(\"-\"*50)\n",
    "\n",
    "const2 = tf.constant([[3,4,5], [3,4,5]]);\n",
    "const1 = tf.constant([[1,2,3], [1,2,3]]);\n",
    "result = tf.add(const1, const2);\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-observation",
   "metadata": {},
   "source": [
    "### Random Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "needed-ballot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10997096  0.3567737 ]\n",
      " [-0.07044305  2.0533187 ]]\n",
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "[[5 8]\n",
      " [7 5]]\n"
     ]
    }
   ],
   "source": [
    "tf_rand_norm = tf.random.normal(shape=(2,2),mean=0,stddev=1.0)\n",
    "print(tf_rand_norm.numpy())\n",
    "\n",
    "tf_rand_uni = tf.random.uniform(shape=(2,2),minval=0,maxval=10,dtype=tf.int32)\n",
    "print(tf_rand_uni.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-geology",
   "metadata": {},
   "source": [
    "### Random Variables\n",
    "##### A variable is a special tensor that is used to store variable values ​​and needs to be initialized with some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "direct-defeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>,\n",
       " <tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
       " array([[[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]],\n",
       " \n",
       "        [[ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring variables\n",
    "var0 = 24 # python variable\n",
    "var1 = tf.Variable(42) # rank 0 tensor\n",
    "var2 = tf.Variable([ [ [0., 1., 2.], [3., 4., 5.] ], [ [6., 7., 8.], [9., 10., 11.] ] ]) #rank 3 tensor\n",
    "var0, var1, var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "portuguese-election",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the datatype can defined explicitly\n",
    "float_var64 = tf.Variable(89, dtype = tf.float64)\n",
    "float_var64.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-soviet",
   "metadata": {},
   "source": [
    "`TensorFlow has a large number of built-in datatypes.`\n",
    "* tf.float16: 16-bit half-precision floating-point.\n",
    "* tf.float32: 32-bit single-precision floating-point.\n",
    "* tf.float64: 64-bit double-precision floating-point.\n",
    "* tf.bfloat16: 16-bit truncated floating-point.\n",
    "* tf.complex64: 64-bit single-precision complex.\n",
    "* tf.complex128: 128-bit double-precision complex.\n",
    "* tf.int8: 8-bit signed integer.\n",
    "* tf.uint8: 8-bit unsigned integer.\n",
    "* tf.uint16: 16-bit unsigned integer.\n",
    "* tf.uint32: 32-bit unsigned integer.\n",
    "* tf.uint64: 64-bit unsigned integer.\n",
    "* tf.int16: 16-bit signed integer.\n",
    "* tf.int32: 32-bit signed integer.\n",
    "* tf.int64: 64-bit signed integer.\n",
    "* tf.bool: Boolean.\n",
    "* tf.string: String.\n",
    "* tf.qint8: Quantized 8-bit signed integer.\n",
    "* tf.quint8: Quantized 8-bit unsigned integer.\n",
    "* tf.qint16: Quantized 16-bit signed integer.\n",
    "* tf.quint16: Quantized 16-bit unsigned integer.\n",
    "* tf.qint32: Quantized 32-bit signed integer.\n",
    "* tf.resource: Handle to a mutable resource.\n",
    "* tf.variant: Values of arbitrary types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-reasoning",
   "metadata": {},
   "source": [
    "#### To reassign a variable, use var.assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "confident-tennessee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=89.0>\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=70.0>\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable(89.)\n",
    "print(var)\n",
    "var_ass = var.assign(70.)\n",
    "print(var_ass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-destiny",
   "metadata": {},
   "source": [
    "#### Tensors can be reshaped and retain the same values which is required for constructing Neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "changed-mathematics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "<tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
      "array([[[10., 11., 12.],\n",
      "        [13., 14., 15.]],\n",
      "\n",
      "       [[16., 17., 18.],\n",
      "        [19., 20., 21.]]], dtype=float32)>\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[10. 11. 12. 13. 14. 15.]\n",
      " [16. 17. 18. 19. 20. 21.]], shape=(2, 6), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([[10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21.]], shape=(1, 12), dtype=float32)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [10., 11., 12.], [13., 14., 15.] ], [ [16., 17., 18.], [19., 20., 21.] ] ]) # tensor variable\n",
    "print(tensor.shape)\n",
    "print(tensor)\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor1 = tf.reshape(tensor,[2,6]) # 2 rows 6 cols\n",
    "#tensor2 = tf.reshape(tensor,[1,12]) # 1 rows 12 cols\n",
    "print(tensor1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor2 = tf.reshape(tensor,[1,12]) # 1 row 12 columns\n",
    "print(tensor2)\n",
    "print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-report",
   "metadata": {},
   "source": [
    "### Rank of Tensor\n",
    "\n",
    "##### The rank of a tensor is defined as the number of dimensions, which is the number of indices that are required to specify any particular element of that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "turned-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [10., 11., 12.], [13., 14., 15.] ], [ [16., 17., 18.], [19., 20., 21.] ] ]) # tensor variable\n",
    "print(tensor.shape)\n",
    "print(tf.rank(tensor)) # the shape is () because the output here is a scalar value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-gambling",
   "metadata": {},
   "source": [
    "#### Specifying an element of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "expressed-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "--------------------------------------------------\n",
      "<tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
      "array([[[10., 11., 12.],\n",
      "        [13., 14., 15.]],\n",
      "\n",
      "       [[16., 17., 18.],\n",
      "        [19., 20., 21.]]], dtype=float32)>\n",
      "--------------------------------------------------\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(18.0, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [10., 11., 12.], [13., 14., 15.] ], [ [16., 17., 18.], [19., 20., 21.] ] ]) # tensor variable\n",
    "print(tensor.shape)\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(tensor)\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(tf.rank(tensor))\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor3 = tensor[1, 0, 2] # slice 1, row 0, column 2\n",
    "print(tensor3)\n",
    "print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aboriginal-membership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10. 11. 12.]\n",
      "  [13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18.]\n",
      "  [19. 20. 21.]]]\n",
      "--------------------------------------------------\n",
      "18.0\n"
     ]
    }
   ],
   "source": [
    "#### Casting a tensor to a NumPy variable\n",
    "print(tensor.numpy())\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(tensor[1, 0, 2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-silver",
   "metadata": {},
   "source": [
    "#### Finding the size or length of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "comparative-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10. 11. 12.]\n",
      "  [13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18.]\n",
      "  [19. 20. 21.]]]\n",
      "--------------------------------------------------\n",
      "12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor.numpy())\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor_size = tf.size(input=tensor).numpy()\n",
    "print(tensor_size)\n",
    "print(\"-\"*50)\n",
    "#the datatype of a tensor\n",
    "tensor3.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-democracy",
   "metadata": {},
   "source": [
    "### Tensorflow mathematical operations\n",
    "##### Can be used as numpy for artificial operations. Tensorflow can not execute these operations on the GPU or TPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "through-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.46985918  0.6765866 ]\n",
      " [-1.0196658   0.125315  ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-1.4355962  -0.57744926]\n",
      " [-1.4484243  -0.20713784]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.96573704  0.09913737]\n",
      " [-2.46809    -0.08182284]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.93264806 0.00982822]\n",
      " [6.0914683  0.00669498]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.38070253 1.104218  ]\n",
      " [0.08474656 0.9214352 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "c = a + b\n",
    "d = tf.square(c)\n",
    "e = tf.exp(c)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "latter-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10. 11. 12.]\n",
      "  [13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18.]\n",
      "  [19. 20. 21.]]]\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[100. 121. 144.]\n",
      "  [169. 196. 225.]]\n",
      "\n",
      " [[256. 289. 324.]\n",
      "  [361. 400. 441.]]], shape=(2, 2, 3), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[40. 44. 48.]\n",
      "  [52. 56. 60.]]\n",
      "\n",
      " [[64. 68. 72.]\n",
      "  [76. 80. 84.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Performing element-wise primitive tensor operations\n",
    "print(tensor.numpy())\n",
    "print(\"-\"*50)\n",
    "print(tensor*tensor)\n",
    "print(\"-\"*50)\n",
    "print(tensor*4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-horizontal",
   "metadata": {},
   "source": [
    "### Transpose Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "forced-while",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[64]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_u = tf.constant([[6,7,6]])\n",
    "matrix_v = tf.constant([[3,4,3]])\n",
    "tf.matmul(matrix_u, tf.transpose(a=matrix_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-estimate",
   "metadata": {},
   "source": [
    "### Casting a tensor to another datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "operational-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10. 11. 12. 13. 14. 15.]\n",
      " [16. 17. 18. 19. 20. 21.]], shape=(2, 6), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[10 11 12 13 14 15]\n",
      " [16 17 18 19 20 21]], shape=(2, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tensor1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "i = tf.cast(tensor1, dtype=tf.int32)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "involved-politics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Casting with truncation\n",
    "j = tf.cast(tf.constant(4.9), dtype=tf.int32)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-algorithm",
   "metadata": {},
   "source": [
    "###  Ragged tensors\n",
    "\n",
    "`A ragged tensor is a tensor having one or more ragged dimensions. Ragged dimensions are dimensions that have slices having various lengths.There are a variety of methods for the declaration of ragged arrays, the simplest way is declaring a constant ragged array.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "qualified-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[9, 7, 4, 3], [], [11, 12, 8], [3], [7, 8]]>\n",
      "--------------------------------------------------\n",
      "tf.Tensor([9 7 4 3], shape=(4,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([], shape=(0,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([11 12  8], shape=(3,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([3], shape=(1,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([7 8], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ragged =tf.ragged.constant([[9, 7, 4, 3], [], [11, 12, 8], [3], [7,8]])\n",
    "print(ragged)\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[0,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[1,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[2,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[3,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-vehicle",
   "metadata": {},
   "source": [
    "### Squared difference of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "polar-colonial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([16,  9,  4, 49, 36])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varx = [4,5,6,1,2]\n",
    "vary = 8\n",
    "varz = tf.math.squared_difference(varx,vary)\n",
    "varz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-thousand",
   "metadata": {},
   "source": [
    "#### Calculate the mean\n",
    "##### Similar to np.mean, except that it infers the return datatype from the input tensor, whereas np.mean allows you to specify the output type\n",
    "\n",
    "`tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "stable-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[8. 9.]\n",
      " [1. 2.]], shape=(2, 2), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([4.5 5.5], shape=(2,), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([[4.5 5.5]], shape=(1, 2), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([8.5 1.5], shape=(2,), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[8.5]\n",
      " [1.5]], shape=(2, 1), dtype=float32)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Defining a constant\n",
    "numbers = tf.constant([[8., 9.], [1., 2.]])\n",
    "print(numbers)\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calculate the mean across all axes\n",
    "print(tf.reduce_mean(input_tensor=numbers)) #default axis = None\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calculate the mean across columns (reduce rows) with this:\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=0))\n",
    "print(\"-\"*50)\n",
    "\n",
    "# When keepdims = True\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=0, keepdims=True)) #the reduced axis is retained with a length of 1\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calculate the mean across rows (reduce columns) with this:\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=1))\n",
    "print(\"-\"*50)\n",
    "\n",
    "# When keepdims= True\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=1, keepdims=True)) #the reduced axis is retained with a length of 1\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-uganda",
   "metadata": {},
   "source": [
    "####  Random values generation\n",
    "* tf.random.normal() outputs a tensor of the given shape filled with values of the dtype type from a normal distribution.\n",
    "* The function is as follows:<br>\n",
    "    \n",
    "`tf.random.normal(shape, mean = 0, stddev =2, dtype=tf.float32, seed=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "frozen-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 8.490959   8.692908 ]\n",
      " [ 7.7909913  6.336467 ]\n",
      " [12.000046   5.7402434]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.normal(shape = (3,2), mean=10, stddev=2, dtype=tf.float32, seed=None, name=None)\n",
    "randon_num = tf.random.normal(shape = (3,2), mean=10.0, stddev=2.0)\n",
    "print(randon_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-immunology",
   "metadata": {},
   "source": [
    "#### Uniform values generation\n",
    "* This outputs a tensor of the given shape filled with values from a uniform distribution in the range minval to maxval, where the lower bound is inclusive but the upper bound isn't.<br>\n",
    "`tf.random.uniform(shape, minval = 0, maxval= None, dtype=tf.float32, seed=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "still-murray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.23750687, 0.41472304, 0.24353361, 0.9110819 ],\n",
       "       [0.7572651 , 0.2054801 , 0.12200975, 0.0467658 ]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape = (2,4), minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "coated-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[4 6]\n",
      " [5 2]], shape=(2, 2), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[9 7]\n",
      " [9 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(11)\n",
    "random_num1 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "random_num2 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "print(random_num1) #Call 1\n",
    "print(\"-\"*50)\n",
    "print(random_num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-blogger",
   "metadata": {},
   "source": [
    "#### Practical example of Random values using Dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "adolescent-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "<tf.Variable 'Variable:0' shape=(10, 1) dtype=int32, numpy=\n",
      "array([[2],\n",
      "       [5],\n",
      "       [6],\n",
      "       [3],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [2]])>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "<tf.Variable 'Variable:0' shape=(10, 1) dtype=int32, numpy=\n",
      "array([[6],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [3],\n",
      "       [5],\n",
      "       [3]])>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[2 6 8]\n",
      " [5 2 7]\n",
      " [6 1 7]\n",
      " [3 5 8]\n",
      " [2 2 4]\n",
      " [2 2 4]\n",
      " [4 4 8]\n",
      " [4 3 7]\n",
      " [4 5 9]\n",
      " [2 3 5]], shape=(10, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dice11 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))\n",
    "print(dice11)\n",
    "print(\"-\"*100)\n",
    "\n",
    "dice12 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))\n",
    "print(dice12)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# lets ADD\n",
    "dice_sum1 = dice11 + dice12\n",
    "# We've got three separate 10x1 matrices. To produce a single 10x3 matrix, we'll concatenate them along dimension 1.\n",
    "finale_matrix = tf.concat(values=[dice11, dice12, dice_sum1], axis=1)\n",
    "print(finale_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-magazine",
   "metadata": {},
   "source": [
    "#### Finding the indices of the largest and smallest element\n",
    ">The following functions are available:\n",
    "    \n",
    ">`tf.argmax(input, axis=None, name=None, output_type=tf.int64 )`\n",
    "\n",
    ">`tf.argmin(input, axis=None, name=None, output_type=tf.int64 )`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "square-cooper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 12  11  51  42   6  16  -8 -19  31], shape=(9,), dtype=int32)\n",
      "index of max;  tf.Tensor(2, shape=(), dtype=int64)\n",
      "Max element:  51\n",
      "index of min:  7\n",
      "Min element:  -19\n"
     ]
    }
   ],
   "source": [
    "# 1-D tensor\n",
    "tensor_1d = tf.constant([12, 11, 51, 42, 6, 16, -8, -19, 31])\n",
    "print(tensor_1d)\n",
    "\n",
    "\n",
    "i = tf.argmax(input=tensor_1d)\n",
    "print('index of max; ', i)\n",
    "print('Max element: ',tensor_1d[i].numpy())\n",
    "\n",
    "\n",
    "i = tf.argmin(input=tensor_1d,axis=0).numpy()\n",
    "print('index of min: ', i)\n",
    "print('Min element: ',tensor_1d[i].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-screening",
   "metadata": {},
   "source": [
    "#### Saving and restoring using a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "gentle-vision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RestoreV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RestoreV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "<tf.Variable 'Variable:0' shape=(2, 4) dtype=int32, numpy=\n",
      "array([[ 5,  6,  9,  3],\n",
      "       [14, 15, 16, 18]])>\n"
     ]
    }
   ],
   "source": [
    "variable1 = tf.Variable([[5,6,9,3],[14,15,16,18]])\n",
    "checkpoint= tf.train.Checkpoint(var=variable1)\n",
    "savepath = checkpoint.save('./vars')\n",
    "variable1.assign([[0,0,0,0],[0,0,0,0]])\n",
    "variable1\n",
    "checkpoint.restore(savepath)\n",
    "print(variable1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-adjustment",
   "metadata": {},
   "source": [
    "#### Using tf.function\n",
    "\n",
    "* `tf.function` is a function that will take a Python function and return a TensorFlow graph. The advantage of this is that graphs can apply optimizations and exploit parallelism in the Python function (func). tf.function is new to TensorFlow 2.<br>\n",
    "\n",
    "`tf.function(func=None,input_signature=None,autograph=True,experimental_autograph_options=None)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "deluxe-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Pow in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_f1_1089 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "def f1(x, y):\n",
    "    return tf.reduce_mean(input_tensor=tf.multiply(x ** 3, 6) + y**3)\n",
    "func = tf.function(f1)\n",
    "x = tf.constant([3., -4.])\n",
    "y = tf.constant([1., 4.])\n",
    "# f1 and f2 return the same value, but f2 executes as a TensorFlow graph\n",
    "assert f1(x,y).numpy() == func(x,y).numpy()\n",
    "#The assert passes, so there is no output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-transparency",
   "metadata": {},
   "source": [
    "## Calculate the gradient\n",
    "### GradientTape\n",
    "* Another difference from numpy is that it can automatically track the gradient of any variable.\n",
    "\n",
    "* Open one GradientTape and `tape.watch()` track variables through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painted-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.49022803 0.80751485]\n",
      " [0.9485126  0.169343  ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(a)\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c,a)\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-distribution",
   "metadata": {},
   "source": [
    "#### For all variables, the calculation is tracked by default and used to find the gradient, so do not use `tape.watch()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afraid-baptist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.49022803 0.80751485]\n",
      " [0.9485126  0.169343  ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(a)\n",
    "with tf.GradientTape() as tape:\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c,a)\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-defense",
   "metadata": {},
   "source": [
    "#### You can GradientTape find higher-order derivatives by opening a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emotional-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.0441233  0.23269019]\n",
      " [0.08397126 0.42837358]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as outer_tape:\n",
    "    with tf.GradientTape() as tape:\n",
    "        c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "        dc_da = tape.gradient(c,a)\n",
    "    d2c_d2a = outer_tape.gradient(dc_da,a)\n",
    "    print(d2c_d2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-empire",
   "metadata": {},
   "source": [
    "# Keras, a High-Level API for TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "challenging-conspiracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2181 - accuracy: 0.9344s - loss: 0.2\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0958 - accuracy: 0.9707s - loss: 0.0959 - accura\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0694 - accuracy: 0.9783\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0522 - accuracy: 0.9836s - loss: 0.0\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0429 - accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25c43b04908>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data = tf.keras.datasets.mnist\n",
    "(train_x,train_y), (test_x, test_y) = mnist_data.load_data()\n",
    "\n",
    "epochs=10\n",
    "batch_size = 32\n",
    "\n",
    "# normalize all the data points and cast the labels to int64\n",
    "train_x, test_x = tf.cast(train_x/255.0, tf.float32), tf.cast(test_x/255.0, tf.float32)\n",
    "train_y, test_y = tf.cast(train_y,tf.int64),tf.cast(test_y,tf.int64)\n",
    "\n",
    "# Model buliding\n",
    "mnistmodel1 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                          tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "                                          tf.keras.layers.Dropout(0.2),\n",
    "                                          tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)])\n",
    "\n",
    "# Compile the model\n",
    "optimiser = tf.keras.optimizers.Adam()\n",
    "mnistmodel1.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the model\n",
    "mnistmodel1.fit(train_x, train_y, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "north-threat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.0637 - accuracy: 0.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06371355843699421, 0.9813]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mnistmodel1.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-language",
   "metadata": {},
   "source": [
    "#### This represents a loss of 0.09 and an accuracy of 0.9801 on the test data. \n",
    "#### An accuracy of 0.98 means that out of 100 test data points, 98 were, on average, correctly identified by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-cloud",
   "metadata": {},
   "source": [
    "### The second way to create a Sequential model\n",
    "### The alternative to passing a list of layers to the Sequential model's constructor is to use the add method, as follows, for the same architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expired-blocking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2428 - accuracy: 0.9297s - l - ETA: 0s - loss: 0.2618 - accuracy: 0. - ETA: 0s - loss: 0.2560 - accu\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1061 - accuracy: 0.9686s - loss: 0.1088 - accuracy:  - ETA: 0s - loss: 0.1\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0741 - accuracy: 0.9772s - loss: 0.0757 - accuracy: 0.97 - ETA:  - ETA: 0s - loss: 0.0742 - accuracy: 0. - ETA: 0s - loss: 0.0742 - accuracy: 0.97 - ETA: 0s - loss: 0.0741 - accuracy - ETA: 0s - loss: 0.0747 - accuracy:  - ETA: 0s - loss: 0.0743 - accu\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0552 - accuracy: 0.9828\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0445 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25c6ec92860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the Architecture & Compiling\n",
    "mnistmodel2 = tf.keras.models.Sequential();\n",
    "mnistmodel2.add(tf.keras.layers.Flatten())\n",
    "mnistmodel2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "mnistmodel2.add(tf.keras.layers.Dropout(0.2))\n",
    "mnistmodel2.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "mnistmodel2.compile (optimizer= tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the model\n",
    "mnistmodel2.fit(train_x, train_y, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "broad-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.0620 - accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.062014164077444, 0.9809]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel2.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-roman",
   "metadata": {},
   "source": [
    "### Keras functional API\n",
    "\n",
    "`The functional API lets you build much more complex architectures than the simple linear stack of Sequential models we have seen previously. It also supports more advanced models. These models include multi-input and multi-output models, models with shared layers, and models with residual connections.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extra-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2214 - accuracy: 0.9333\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0970 - accuracy: 0.9697\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0700 - accuracy: 0.9779\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0516 - accuracy: 0.9833s - loss: 0.0511 - ac\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0427 - accuracy: 0.9861s - l\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0367 - accuracy: 0.9879\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0320 - accuracy: 0.9891s - loss: 0.0319 - ac\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0268 - accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0232 - accuracy: 0.9924s - loss:\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0223 - accuracy: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25c6ec5cb70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_x,train_y), (test_x, test_y) = mnist.load_data()\n",
    "train_x, test_x = train_x/255.0, test_x/255.0\n",
    "epochs=10\n",
    "\n",
    "# buliding the architecture\n",
    "inputs = tf.keras.Input(shape=(28,28)) # Returns a 'placeholder' tensor\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(512, activation='relu',name='d1')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "predictions = tf.keras.layers.Dense(10,activation=tf.nn.softmax, name='d2')(x)\n",
    "mnistmodel3 = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# compile and fit the model\n",
    "optimiser = tf.keras.optimizers.Adam()\n",
    "mnistmodel3.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "mnistmodel3.fit(train_x, train_y, batch_size=32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adult-sellers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.0715 - accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07149309444894061, 0.9819]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "mnistmodel3.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-palace",
   "metadata": {},
   "source": [
    "### Subclassing the Keras Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "medieval-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MNISTModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        # Define your layers here.\n",
    "        inputs = tf.keras.Input(shape=(28,28)) # Returns a placeholder tensor\n",
    "        self.x0 = tf.keras.layers.Flatten()\n",
    "        self.x1 = tf.keras.layers.Dense(512, activation='relu',name='d1')\n",
    "        self.x2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.predictions = tf.keras.layers.Dense(10,activation=tf.nn.softmax, name='d2')\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "    # This is where to define your forward pass\n",
    "    # using the layers previously defined in `__init__`\n",
    "        x = self.x0(inputs)\n",
    "        x = self.x1(x)\n",
    "        x = self.x2(x)\n",
    "        return self.predictions(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "verbal-belly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2200 - accuracy: 0.9350\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0971 - accuracy: 0.9701\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0684 - accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0540 - accuracy: 0.9828s - loss: 0.0533 - accuracy:  - ETA: 0s -\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0442 - accuracy: 0.9851\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0362 - accuracy: 0.9879\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0315 - accuracy: 0.9894\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0274 - accuracy: 0.9908s - loss: 0.025\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0248 - accuracy: 0.9914\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0199 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d0b064eb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel4 = MNISTModel()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_x,train_y), (test_x, test_y) = mnist.load_data()\n",
    "train_x, test_x = train_x/255.0, test_x/255.0\n",
    "\n",
    "# Compile and Fit\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(train_x)/batch_size\n",
    "print(steps_per_epoch)\n",
    "mnistmodel4.compile (optimizer= tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "mnistmodel4.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "earned-kernel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 85us/sample - loss: 0.0756 - accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07558068492501188, 0.9808]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel4.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-verse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
