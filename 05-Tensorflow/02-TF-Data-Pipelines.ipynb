{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "higher-setting",
   "metadata": {},
   "source": [
    "# Using Data Pipelines\n",
    "* Data may also be passed into the fit method as a tf.data.Dataset() iterator\n",
    "* The from_tensor_slices() method converts the NumPy arrays into a dataset\n",
    "* The batch() and shuffle() methods chained together. \n",
    "\n",
    "* Next, the map() method invokes a method on the input images, x, that randomly flips one in two of them across the y-axis, effectively increasing the size of the image set\n",
    "\n",
    "* Finally, the repeat() method means that the dataset will be re-fed from the beginning when its end is reached (continuously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "christian-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "south-cursor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1875 steps\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3616 - accuracy: 0.8909\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1780 - accuracy: 0.9458\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1376 - accuracy: 0.9576\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1137 - accuracy: 0.9645\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0996 - accuracy: 0.9687\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0917 - accuracy: 0.9713\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0799 - accuracy: 0.9746\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0755 - accuracy: 0.9760\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0686 - accuracy: 0.9784\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.97 - 5s 3ms/step - loss: 0.0645 - accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x241be95dac8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_x,train_y), (test_x, test_y) = mnist.load_data()\n",
    "train_x, test_x = train_x/255.0, test_x/255.0\n",
    "\n",
    "epochs=10\n",
    "batch_size = 32\n",
    "buffer_size = 10000\n",
    "# training dataset\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(32).shuffle(10000)\n",
    "training_dataset = training_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "training_dataset = training_dataset.repeat()\n",
    "\n",
    "#testing dataset\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size).shuffle(10000)\n",
    "testing_dataset = training_dataset.repeat()\n",
    "\n",
    "# building the model architecture\n",
    "model5 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                     tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
    "                                     tf.keras.layers.Dropout(0.2),\n",
    "                                     tf.keras.layers.Dense(10,activation=tf.nn.softmax) ])\n",
    "\n",
    "\n",
    "# Compling the model\n",
    "steps_per_epoch = len(train_x)//batch_size #required becuase of the repeat() on the dataset\n",
    "optimiser = tf.keras.optimizers.Adam()\n",
    "model5.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fitting the model\n",
    "# Now in the fit() function, we can pass the dataset directly in, as follows:\n",
    "model5.fit(training_dataset, epochs=epochs, steps_per_epoch = steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-clone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 59ms/step - loss: 0.0422 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04220453345624264, 0.990625]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(testing_dataset,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-israel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepted-fetish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1875 steps\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5988 - accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4567 - accuracy: 0.8345\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4243 - accuracy: 0.8456\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3974 - accuracy: 0.8546\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3833 - accuracy: 0.8606\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3696 - accuracy: 0.8652\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3587 - accuracy: 0.8681\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3502 - accuracy: 0.8716\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3389 - accuracy: 0.8753\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3339 - accuracy: 0.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x241a7adcd30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "f_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_x,train_y), (test_x, test_y) = f_mnist.load_data()\n",
    "train_x, test_x = train_x/255.0, test_x/255.0\n",
    "\n",
    "epochs=10\n",
    "batch_size = 32\n",
    "buffer_size = 10000\n",
    "# training dataset\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(32).shuffle(10000)\n",
    "training_dataset = training_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "training_dataset = training_dataset.repeat()\n",
    "\n",
    "#testing dataset\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size).shuffle(10000)\n",
    "testing_dataset = training_dataset.repeat()\n",
    "\n",
    "# building the model architecture\n",
    "model5 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                     tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
    "                                     tf.keras.layers.Dropout(0.2),\n",
    "                                     tf.keras.layers.Dense(10,activation=tf.nn.softmax) ])\n",
    "\n",
    "\n",
    "# Compling the model\n",
    "steps_per_epoch = len(train_x)//batch_size #required becuase of the repeat() on the dataset\n",
    "optimiser = tf.keras.optimizers.Adam()\n",
    "model5.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fitting the model\n",
    "# Now in the fit() function, we can pass the dataset directly in, as follows:\n",
    "model5.fit(training_dataset, epochs=epochs, steps_per_epoch = steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "diverse-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 72ms/step - loss: 0.3034 - accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30344298779964446, 0.884375]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(testing_dataset,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technological-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='log/{}/'.format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loving-mercy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1875 steps, validate for 3 steps\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3264 - accuracy: 0.8805 - val_loss: 0.3538 - val_accuracy: 0.8854\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3186 - accuracy: 0.8826 - val_loss: 0.2634 - val_accuracy: 0.8854\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3167 - accuracy: 0.8820 - val_loss: 0.1778 - val_accuracy: 0.9271\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3119 - accuracy: 0.8850 - val_loss: 0.2664 - val_accuracy: 0.8854\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3056 - accuracy: 0.8877 - val_loss: 0.1442 - val_accuracy: 0.9688\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2989 - accuracy: 0.8886 - val_loss: 0.1887 - val_accuracy: 0.9479\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2953 - accuracy: 0.8913 - val_loss: 0.3010 - val_accuracy: 0.8646\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2919 - accuracy: 0.8931 - val_loss: 0.3045 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2882 - accuracy: 0.8932 - val_loss: 0.2649 - val_accuracy: 0.8854\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2869 - accuracy: 0.8931 - val_loss: 0.2126 - val_accuracy: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x241e869b710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(training_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "          validation_data=testing_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coated-wallace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 32ms/step - loss: 0.2833 - accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28329772800207137, 0.89375]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(testing_dataset,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-roman",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
