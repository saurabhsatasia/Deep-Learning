{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "universal-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ancient-space",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Keras version: 2.2.4-tf\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "organic-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "WARNING:tensorflow:From <ipython-input-9-e16782003dfe>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU\n",
      "GPU #0?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "variable = tf.Variable([3, 3])\n",
    "if tf.test.is_gpu_available():\n",
    "    print('GPU')\n",
    "    print('GPU #0?')\n",
    "    print(variable.device.endswith('GPU:0'))\n",
    "else:\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secure-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sweet-clinton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9964483664649540287\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3135687886\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12906192970671526293\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "split-makeup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Run on the GPU\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-catch",
   "metadata": {},
   "source": [
    "### Tensor Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hairy-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "tf_constant = tf.constant(42)\n",
    "print(tf_constant)\n",
    "print(tf_constant.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "regulation-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(99, shape=(), dtype=int64)\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "tf_const1 = tf.constant(99, dtype = tf.int64)\n",
    "print(tf_const1)\n",
    "print(tf_const1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "developing-aside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 2]\n",
      " [9 5]], shape=(2, 2), dtype=int32)\n",
      "[[4 2]\n",
      " [9 5]]\n"
     ]
    }
   ],
   "source": [
    "tf_arr = tf.constant([[4,2],[9,5]])\n",
    "print(tf_arr)\n",
    "print(tf_arr.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-steam",
   "metadata": {},
   "source": [
    "#### Commonly used method is to generate constant tf.ones and the tf.zeros like of numpy np.ones & np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hidden-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(3, 2), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[4 6 8]\n",
      " [4 6 8]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.ones(shape=(2,3)))\n",
    "print(\"-\"*50)\n",
    "print(tf.zeros(shape=(3,2)))\n",
    "print(\"-\"*50)\n",
    "\n",
    "const2 = tf.constant([[3,4,5], [3,4,5]]);\n",
    "const1 = tf.constant([[1,2,3], [1,2,3]]);\n",
    "result = tf.add(const1, const2);\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-potential",
   "metadata": {},
   "source": [
    "### Random Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affected-wound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10997096  0.3567737 ]\n",
      " [-0.07044305  2.0533187 ]]\n",
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "[[5 8]\n",
      " [7 5]]\n"
     ]
    }
   ],
   "source": [
    "tf_rand_norm = tf.random.normal(shape=(2,2),mean=0,stddev=1.0)\n",
    "print(tf_rand_norm.numpy())\n",
    "\n",
    "tf_rand_uni = tf.random.uniform(shape=(2,2),minval=0,maxval=10,dtype=tf.int32)\n",
    "print(tf_rand_uni.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-verse",
   "metadata": {},
   "source": [
    "### Random Variables\n",
    "##### A variable is a special tensor that is used to store variable values ​​and needs to be initialized with some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "supposed-venture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>,\n",
       " <tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
       " array([[[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]],\n",
       " \n",
       "        [[ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring variables\n",
    "var0 = 24 # python variable\n",
    "var1 = tf.Variable(42) # rank 0 tensor\n",
    "var2 = tf.Variable([ [ [0., 1., 2.], [3., 4., 5.] ], [ [6., 7., 8.], [9., 10., 11.] ] ]) #rank 3 tensor\n",
    "var0, var1, var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "expensive-brush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the datatype can defined explicitly\n",
    "float_var64 = tf.Variable(89, dtype = tf.float64)\n",
    "float_var64.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-pharmacy",
   "metadata": {},
   "source": [
    "`TensorFlow has a large number of built-in datatypes.`\n",
    "* tf.float16: 16-bit half-precision floating-point.\n",
    "* tf.float32: 32-bit single-precision floating-point.\n",
    "* tf.float64: 64-bit double-precision floating-point.\n",
    "* tf.bfloat16: 16-bit truncated floating-point.\n",
    "* tf.complex64: 64-bit single-precision complex.\n",
    "* tf.complex128: 128-bit double-precision complex.\n",
    "* tf.int8: 8-bit signed integer.\n",
    "* tf.uint8: 8-bit unsigned integer.\n",
    "* tf.uint16: 16-bit unsigned integer.\n",
    "* tf.uint32: 32-bit unsigned integer.\n",
    "* tf.uint64: 64-bit unsigned integer.\n",
    "* tf.int16: 16-bit signed integer.\n",
    "* tf.int32: 32-bit signed integer.\n",
    "* tf.int64: 64-bit signed integer.\n",
    "* tf.bool: Boolean.\n",
    "* tf.string: String.\n",
    "* tf.qint8: Quantized 8-bit signed integer.\n",
    "* tf.quint8: Quantized 8-bit unsigned integer.\n",
    "* tf.qint16: Quantized 16-bit signed integer.\n",
    "* tf.quint16: Quantized 16-bit unsigned integer.\n",
    "* tf.qint32: Quantized 32-bit signed integer.\n",
    "* tf.resource: Handle to a mutable resource.\n",
    "* tf.variant: Values of arbitrary types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-opposition",
   "metadata": {},
   "source": [
    "#### To reassign a variable, use var.assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "welsh-stereo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=89.0>\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=70.0>\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable(89.)\n",
    "print(var)\n",
    "var_ass = var.assign(70.)\n",
    "print(var_ass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-blind",
   "metadata": {},
   "source": [
    "#### Tensors can be reshaped and retain the same values which is required for constructing Neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "perfect-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "<tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
      "array([[[10., 11., 12.],\n",
      "        [13., 14., 15.]],\n",
      "\n",
      "       [[16., 17., 18.],\n",
      "        [19., 20., 21.]]], dtype=float32)>\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[10. 11. 12. 13. 14. 15.]\n",
      " [16. 17. 18. 19. 20. 21.]], shape=(2, 6), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([[10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21.]], shape=(1, 12), dtype=float32)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [10., 11., 12.], [13., 14., 15.] ], [ [16., 17., 18.], [19., 20., 21.] ] ]) # tensor variable\n",
    "print(tensor.shape)\n",
    "print(tensor)\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor1 = tf.reshape(tensor,[2,6]) # 2 rows 6 cols\n",
    "#tensor2 = tf.reshape(tensor,[1,12]) # 1 rows 12 cols\n",
    "print(tensor1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor2 = tf.reshape(tensor,[1,12]) # 1 row 12 columns\n",
    "print(tensor2)\n",
    "print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-surfing",
   "metadata": {},
   "source": [
    "### Rank of Tensor\n",
    "\n",
    "##### The rank of a tensor is defined as the number of dimensions, which is the number of indices that are required to specify any particular element of that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mechanical-tobacco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [10., 11., 12.], [13., 14., 15.] ], [ [16., 17., 18.], [19., 20., 21.] ] ]) # tensor variable\n",
    "print(tensor.shape)\n",
    "print(tf.rank(tensor)) # the shape is () because the output here is a scalar value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-helena",
   "metadata": {},
   "source": [
    "#### Specifying an element of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "regional-tiffany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "--------------------------------------------------\n",
      "<tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
      "array([[[10., 11., 12.],\n",
      "        [13., 14., 15.]],\n",
      "\n",
      "       [[16., 17., 18.],\n",
      "        [19., 20., 21.]]], dtype=float32)>\n",
      "--------------------------------------------------\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(18.0, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [10., 11., 12.], [13., 14., 15.] ], [ [16., 17., 18.], [19., 20., 21.] ] ]) # tensor variable\n",
    "print(tensor.shape)\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(tensor)\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(tf.rank(tensor))\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor3 = tensor[1, 0, 2] # slice 1, row 0, column 2\n",
    "print(tensor3)\n",
    "print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sitting-survivor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10. 11. 12.]\n",
      "  [13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18.]\n",
      "  [19. 20. 21.]]]\n",
      "--------------------------------------------------\n",
      "18.0\n"
     ]
    }
   ],
   "source": [
    "#### Casting a tensor to a NumPy variable\n",
    "print(tensor.numpy())\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(tensor[1, 0, 2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-carbon",
   "metadata": {},
   "source": [
    "#### Finding the size or length of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "veterinary-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10. 11. 12.]\n",
      "  [13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18.]\n",
      "  [19. 20. 21.]]]\n",
      "--------------------------------------------------\n",
      "12\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor.numpy())\n",
    "print(\"-\"*50)\n",
    "\n",
    "tensor_size = tf.size(input=tensor).numpy()\n",
    "print(tensor_size)\n",
    "print(\"-\"*50)\n",
    "#the datatype of a tensor\n",
    "tensor3.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-federal",
   "metadata": {},
   "source": [
    "### Tensorflow mathematical operations\n",
    "##### Can be used as numpy for artificial operations. Tensorflow can not execute these operations on the GPU or TPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "foster-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.46985918  0.6765866 ]\n",
      " [-1.0196658   0.125315  ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-1.4355962  -0.57744926]\n",
      " [-1.4484243  -0.20713784]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.96573704  0.09913737]\n",
      " [-2.46809    -0.08182284]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.93264806 0.00982822]\n",
      " [6.0914683  0.00669498]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.38070253 1.104218  ]\n",
      " [0.08474656 0.9214352 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "c = a + b\n",
    "d = tf.square(c)\n",
    "e = tf.exp(c)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "atlantic-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10. 11. 12.]\n",
      "  [13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18.]\n",
      "  [19. 20. 21.]]]\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[100. 121. 144.]\n",
      "  [169. 196. 225.]]\n",
      "\n",
      " [[256. 289. 324.]\n",
      "  [361. 400. 441.]]], shape=(2, 2, 3), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[40. 44. 48.]\n",
      "  [52. 56. 60.]]\n",
      "\n",
      " [[64. 68. 72.]\n",
      "  [76. 80. 84.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Performing element-wise primitive tensor operations\n",
    "print(tensor.numpy())\n",
    "print(\"-\"*50)\n",
    "print(tensor*tensor)\n",
    "print(\"-\"*50)\n",
    "print(tensor*4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-overview",
   "metadata": {},
   "source": [
    "### Transpose Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "southeast-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[64]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_u = tf.constant([[6,7,6]])\n",
    "matrix_v = tf.constant([[3,4,3]])\n",
    "tf.matmul(matrix_u, tf.transpose(a=matrix_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-extreme",
   "metadata": {},
   "source": [
    "### Casting a tensor to another datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "lightweight-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10. 11. 12. 13. 14. 15.]\n",
      " [16. 17. 18. 19. 20. 21.]], shape=(2, 6), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[10 11 12 13 14 15]\n",
      " [16 17 18 19 20 21]], shape=(2, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tensor1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "i = tf.cast(tensor1, dtype=tf.int32)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "given-stewart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Casting with truncation\n",
    "j = tf.cast(tf.constant(4.9), dtype=tf.int32)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-replica",
   "metadata": {},
   "source": [
    "###  Ragged tensors\n",
    "\n",
    "`A ragged tensor is a tensor having one or more ragged dimensions. Ragged dimensions are dimensions that have slices having various lengths.There are a variety of methods for the declaration of ragged arrays, the simplest way is declaring a constant ragged array.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "convinced-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[9, 7, 4, 3], [], [11, 12, 8], [3], [7, 8]]>\n",
      "--------------------------------------------------\n",
      "tf.Tensor([9 7 4 3], shape=(4,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([], shape=(0,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([11 12  8], shape=(3,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([3], shape=(1,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([7 8], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ragged =tf.ragged.constant([[9, 7, 4, 3], [], [11, 12, 8], [3], [7,8]])\n",
    "print(ragged)\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[0,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[1,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[2,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[3,:])\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(ragged[4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-score",
   "metadata": {},
   "source": [
    "### Squared difference of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "mounted-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([16,  9,  4, 49, 36])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varx = [4,5,6,1,2]\n",
    "vary = 8\n",
    "varz = tf.math.squared_difference(varx,vary)\n",
    "varz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-adjustment",
   "metadata": {},
   "source": [
    "#### Calculate the mean\n",
    "##### Similar to np.mean, except that it infers the return datatype from the input tensor, whereas np.mean allows you to specify the output type\n",
    "\n",
    "`tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "curious-wesley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[8. 9.]\n",
      " [1. 2.]], shape=(2, 2), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([4.5 5.5], shape=(2,), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([[4.5 5.5]], shape=(1, 2), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor([8.5 1.5], shape=(2,), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[8.5]\n",
      " [1.5]], shape=(2, 1), dtype=float32)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Defining a constant\n",
    "numbers = tf.constant([[8., 9.], [1., 2.]])\n",
    "print(numbers)\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calculate the mean across all axes\n",
    "print(tf.reduce_mean(input_tensor=numbers)) #default axis = None\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calculate the mean across columns (reduce rows) with this:\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=0))\n",
    "print(\"-\"*50)\n",
    "\n",
    "# When keepdims = True\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=0, keepdims=True)) #the reduced axis is retained with a length of 1\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calculate the mean across rows (reduce columns) with this:\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=1))\n",
    "print(\"-\"*50)\n",
    "\n",
    "# When keepdims= True\n",
    "print(tf.reduce_mean(input_tensor=numbers, axis=1, keepdims=True)) #the reduced axis is retained with a length of 1\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-contact",
   "metadata": {},
   "source": [
    "####  Random values generation\n",
    "* tf.random.normal() outputs a tensor of the given shape filled with values of the dtype type from a normal distribution.\n",
    "* The function is as follows:<br>\n",
    "    \n",
    "`tf.random.normal(shape, mean = 0, stddev =2, dtype=tf.float32, seed=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dimensional-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 8.490959   8.692908 ]\n",
      " [ 7.7909913  6.336467 ]\n",
      " [12.000046   5.7402434]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.normal(shape = (3,2), mean=10, stddev=2, dtype=tf.float32, seed=None, name=None)\n",
    "randon_num = tf.random.normal(shape = (3,2), mean=10.0, stddev=2.0)\n",
    "print(randon_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-indonesia",
   "metadata": {},
   "source": [
    "#### Uniform values generation\n",
    "* This outputs a tensor of the given shape filled with values from a uniform distribution in the range minval to maxval, where the lower bound is inclusive but the upper bound isn't.<br>\n",
    "`tf.random.uniform(shape, minval = 0, maxval= None, dtype=tf.float32, seed=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "informative-belly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.23750687, 0.41472304, 0.24353361, 0.9110819 ],\n",
       "       [0.7572651 , 0.2054801 , 0.12200975, 0.0467658 ]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape = (2,4), minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "academic-foster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[4 6]\n",
      " [5 2]], shape=(2, 2), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[9 7]\n",
      " [9 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(11)\n",
    "random_num1 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "random_num2 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "print(random_num1) #Call 1\n",
    "print(\"-\"*50)\n",
    "print(random_num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-registration",
   "metadata": {},
   "source": [
    "#### Practical example of Random values using Dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "incident-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "<tf.Variable 'Variable:0' shape=(10, 1) dtype=int32, numpy=\n",
      "array([[2],\n",
      "       [5],\n",
      "       [6],\n",
      "       [3],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [2]])>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Executing op RandomUniformInt in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "<tf.Variable 'Variable:0' shape=(10, 1) dtype=int32, numpy=\n",
      "array([[6],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [3],\n",
      "       [5],\n",
      "       [3]])>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[2 6 8]\n",
      " [5 2 7]\n",
      " [6 1 7]\n",
      " [3 5 8]\n",
      " [2 2 4]\n",
      " [2 2 4]\n",
      " [4 4 8]\n",
      " [4 3 7]\n",
      " [4 5 9]\n",
      " [2 3 5]], shape=(10, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dice11 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))\n",
    "print(dice11)\n",
    "print(\"-\"*100)\n",
    "\n",
    "dice12 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))\n",
    "print(dice12)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# lets ADD\n",
    "dice_sum1 = dice11 + dice12\n",
    "# We've got three separate 10x1 matrices. To produce a single 10x3 matrix, we'll concatenate them along dimension 1.\n",
    "finale_matrix = tf.concat(values=[dice11, dice12, dice_sum1], axis=1)\n",
    "print(finale_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-harmony",
   "metadata": {},
   "source": [
    "#### Finding the indices of the largest and smallest element\n",
    ">The following functions are available:\n",
    "    \n",
    ">`tf.argmax(input, axis=None, name=None, output_type=tf.int64 )`\n",
    "\n",
    ">`tf.argmin(input, axis=None, name=None, output_type=tf.int64 )`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "chinese-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 12  11  51  42   6  16  -8 -19  31], shape=(9,), dtype=int32)\n",
      "index of max;  tf.Tensor(2, shape=(), dtype=int64)\n",
      "Max element:  51\n",
      "index of min:  7\n",
      "Min element:  -19\n"
     ]
    }
   ],
   "source": [
    "# 1-D tensor\n",
    "tensor_1d = tf.constant([12, 11, 51, 42, 6, 16, -8, -19, 31])\n",
    "print(tensor_1d)\n",
    "\n",
    "\n",
    "i = tf.argmax(input=tensor_1d)\n",
    "print('index of max; ', i)\n",
    "print('Max element: ',tensor_1d[i].numpy())\n",
    "\n",
    "\n",
    "i = tf.argmin(input=tensor_1d,axis=0).numpy()\n",
    "print('index of min: ', i)\n",
    "print('Min element: ',tensor_1d[i].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-artist",
   "metadata": {},
   "source": [
    "#### Saving and restoring using a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "another-corpus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RestoreV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RestoreV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "<tf.Variable 'Variable:0' shape=(2, 4) dtype=int32, numpy=\n",
      "array([[ 5,  6,  9,  3],\n",
      "       [14, 15, 16, 18]])>\n"
     ]
    }
   ],
   "source": [
    "variable1 = tf.Variable([[5,6,9,3],[14,15,16,18]])\n",
    "checkpoint= tf.train.Checkpoint(var=variable1)\n",
    "savepath = checkpoint.save('./vars')\n",
    "variable1.assign([[0,0,0,0],[0,0,0,0]])\n",
    "variable1\n",
    "checkpoint.restore(savepath)\n",
    "print(variable1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-consent",
   "metadata": {},
   "source": [
    "#### Using tf.function\n",
    "\n",
    "* `tf.function` is a function that will take a Python function and return a TensorFlow graph. The advantage of this is that graphs can apply optimizations and exploit parallelism in the Python function (func). tf.function is new to TensorFlow 2.<br>\n",
    "\n",
    "`tf.function(func=None,input_signature=None,autograph=True,experimental_autograph_options=None)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "announced-union",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Pow in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_f1_1089 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "def f1(x, y):\n",
    "    return tf.reduce_mean(input_tensor=tf.multiply(x ** 3, 6) + y**3)\n",
    "func = tf.function(f1)\n",
    "x = tf.constant([3., -4.])\n",
    "y = tf.constant([1., 4.])\n",
    "# f1 and f2 return the same value, but f2 executes as a TensorFlow graph\n",
    "assert f1(x,y).numpy() == func(x,y).numpy()\n",
    "#The assert passes, so there is no output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-modern",
   "metadata": {},
   "source": [
    "## Calculate the gradient\n",
    "### GradientTape\n",
    "* Another difference from numpy is that it can automatically track the gradient of any variable.\n",
    "\n",
    "* Open one GradientTape and `tape.watch()` track variables through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coupled-rachel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.49022803 0.80751485]\n",
      " [0.9485126  0.169343  ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(a)\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c,a)\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-priest",
   "metadata": {},
   "source": [
    "#### For all variables, the calculation is tracked by default and used to find the gradient, so do not use `tape.watch()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generous-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.49022803 0.80751485]\n",
      " [0.9485126  0.169343  ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(a)\n",
    "with tf.GradientTape() as tape:\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c,a)\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-dimension",
   "metadata": {},
   "source": [
    "#### You can GradientTape find higher-order derivatives by opening a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fundamental-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.0441233  0.23269019]\n",
      " [0.08397126 0.42837358]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as outer_tape:\n",
    "    with tf.GradientTape() as tape:\n",
    "        c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "        dc_da = tape.gradient(c,a)\n",
    "    d2c_d2a = outer_tape.gradient(dc_da,a)\n",
    "    print(d2c_d2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-clone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
