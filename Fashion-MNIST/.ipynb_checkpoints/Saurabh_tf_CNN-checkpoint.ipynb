{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-stand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "partial-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generous-luxury",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Call_back(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, acc_threshold=0.98, print_msg=True):\n",
    "        super(Call_back, self).__init__()\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.print_msg = print_msg\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > self.acc_threshold):\n",
    "            if self.print_msg:\n",
    "                print(\"\\n-->Reached 96% accuracy so cancelling the training\")\n",
    "            self.model.stop_training = True\n",
    "        else:\n",
    "            if self.print_msg:\n",
    "                print(\"\\nAccuracy not high enough. Starting another epoch...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broke-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = Call_back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "natural-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "public-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000,28,28,1))\n",
    "x_test = x_test.reshape((10000,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accomplished-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fitting-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(act_func='relu', output_class=10):\n",
    "    if act_func=='relu':\n",
    "        activation=tf.nn.relu\n",
    "    elif act_func=='sigmoid':\n",
    "        activation=tf.nn.sigmoid\n",
    "    elif act_func=='tanh':\n",
    "        activation=tf.nn.tanh\n",
    "    elif act_func=='swish':\n",
    "        activation=tf.nn.swish\n",
    "        \n",
    "        \n",
    "    classifier = Sequential()\n",
    "\n",
    "    #Step 1- Convolution\n",
    "    classifier.add(Conv2D(128, (4, 4), input_shape = (28, 28,1), activation = 'relu'))\n",
    "    classifier.add(Conv2D(64, (4, 4), activation = activation))\n",
    "\n",
    "    #adding another layer\n",
    "    classifier.add(Conv2D(32, (4, 4), activation = activation))\n",
    "\n",
    "    #Pooling it\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    #Adding another layer\n",
    "    classifier.add(Conv2D(32, (4, 4), activation = activation))\n",
    "    \n",
    "    #Pooling\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    #Flatten\n",
    "    classifier.add(Flatten())\n",
    "    \n",
    "    #Step 4- Full connection\n",
    "    classifier.add(Dense(units = 128, activation = activation))\n",
    "    classifier.add(Dense(units = 10, activation = 'softmax'))\n",
    "    classifier.add(Dropout(0.01))\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "southwest-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(act_func='swish', output_class=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sacred-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 128)       2176      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 64)        131136    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 19, 19, 32)        32800     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 32)          16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               36992     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 220,810\n",
      "Trainable params: 220,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tutorial-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.6348 - accuracy: 0.8029\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 360s 6ms/sample - loss: 0.6351 - accuracy: 0.8029\n",
      "Epoch 2/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.4291 - accuracy: 0.8702\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 362s 6ms/sample - loss: 0.4290 - accuracy: 0.8702\n",
      "Epoch 3/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8852\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 359s 6ms/sample - loss: 0.3852 - accuracy: 0.8852\n",
      "Epoch 4/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8956\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 367s 6ms/sample - loss: 0.3526 - accuracy: 0.8956\n",
      "Epoch 5/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.9030\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 346s 6ms/sample - loss: 0.3288 - accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.3031 - accuracy: 0.9090\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 333s 6ms/sample - loss: 0.3030 - accuracy: 0.9090\n",
      "Epoch 7/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.9146\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 332s 6ms/sample - loss: 0.2850 - accuracy: 0.9147\n",
      "Epoch 8/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.9189\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 300s 5ms/sample - loss: 0.2742 - accuracy: 0.9189\n",
      "Epoch 9/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.2598 - accuracy: 0.9228\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 277s 5ms/sample - loss: 0.2600 - accuracy: 0.9228\n",
      "Epoch 10/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.9265\n",
      "Accuracy not high enough. Starting another epoch...\n",
      "\n",
      "60000/60000 [==============================] - 246s 4ms/sample - loss: 0.2444 - accuracy: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2655b5c7828>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "surrounded-former",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 738us/sample - loss: 0.2913 - accuracy: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29129293778687715, 0.907]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "filled-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Fashion_mnist_9070.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "applicable-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator( shear_range=0.2,\n",
    "                              zoom_range=0.2,\n",
    "                              horizontal_flip=True,\n",
    "                              rotation_range=20)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "federal-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same',input_shape=(28,28,1)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "meaningful-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_vl, y_tr,y_vl = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "scientific-rotation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 342s 7ms/sample - loss: 0.5399 - accuracy: 0.8037 - val_loss: 0.7887 - val_accuracy: 0.7121\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 346s 7ms/sample - loss: 0.3537 - accuracy: 0.8696 - val_loss: 0.2904 - val_accuracy: 0.8888\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 366s 8ms/sample - loss: 0.3024 - accuracy: 0.8896 - val_loss: 0.2784 - val_accuracy: 0.8959\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 352s 7ms/sample - loss: 0.2739 - accuracy: 0.9021 - val_loss: 0.2723 - val_accuracy: 0.9022\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 348s 7ms/sample - loss: 0.2522 - accuracy: 0.9096 - val_loss: 0.2605 - val_accuracy: 0.9054\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 355s 7ms/sample - loss: 0.2404 - accuracy: 0.9136 - val_loss: 0.2367 - val_accuracy: 0.9112\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 351s 7ms/sample - loss: 0.2155 - accuracy: 0.9211 - val_loss: 0.2349 - val_accuracy: 0.9154\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 355s 7ms/sample - loss: 0.2075 - accuracy: 0.9262 - val_loss: 0.2548 - val_accuracy: 0.9089\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 348s 7ms/sample - loss: 0.1966 - accuracy: 0.9290 - val_loss: 0.2061 - val_accuracy: 0.9255\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 535s 11ms/sample - loss: 0.1821 - accuracy: 0.9340 - val_loss: 0.2101 - val_accuracy: 0.9305\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 540s 11ms/sample - loss: 0.1720 - accuracy: 0.9373 - val_loss: 0.2010 - val_accuracy: 0.9317\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 568s 12ms/sample - loss: 0.1660 - accuracy: 0.9404 - val_loss: 0.2132 - val_accuracy: 0.9236\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 568s 12ms/sample - loss: 0.1612 - accuracy: 0.9421 - val_loss: 0.1949 - val_accuracy: 0.9348\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 564s 12ms/sample - loss: 0.1552 - accuracy: 0.9442 - val_loss: 0.1933 - val_accuracy: 0.9339\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 2552s 53ms/sample - loss: 0.1407 - accuracy: 0.9494 - val_loss: 0.2011 - val_accuracy: 0.9361\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 344s 7ms/sample - loss: 0.1341 - accuracy: 0.9505 - val_loss: 0.2059 - val_accuracy: 0.9336\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 342s 7ms/sample - loss: 0.1346 - accuracy: 0.9514 - val_loss: 0.2010 - val_accuracy: 0.9305\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 345s 7ms/sample - loss: 0.0948 - accuracy: 0.9641 - val_loss: 0.1931 - val_accuracy: 0.9418\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 347s 7ms/sample - loss: 0.0805 - accuracy: 0.9696 - val_loss: 0.1994 - val_accuracy: 0.9433\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 349s 7ms/sample - loss: 0.0755 - accuracy: 0.9726 - val_loss: 0.2040 - val_accuracy: 0.9412\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 349s 7ms/sample - loss: 0.0659 - accuracy: 0.9750 - val_loss: 0.2211 - val_accuracy: 0.9429\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 350s 7ms/sample - loss: 0.0575 - accuracy: 0.9780 - val_loss: 0.2560 - val_accuracy: 0.9429\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 349s 7ms/sample - loss: 0.0569 - accuracy: 0.9787 - val_loss: 0.2300 - val_accuracy: 0.9421\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 348s 7ms/sample - loss: 0.0553 - accuracy: 0.9791 - val_loss: 0.2412 - val_accuracy: 0.9419\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 344s 7ms/sample - loss: 0.0510 - accuracy: 0.9809 - val_loss: 0.2435 - val_accuracy: 0.9424\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 349s 7ms/sample - loss: 0.0477 - accuracy: 0.9821 - val_loss: 0.2655 - val_accuracy: 0.9438\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 344s 7ms/sample - loss: 0.0484 - accuracy: 0.9824 - val_loss: 0.2586 - val_accuracy: 0.9437\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 346s 7ms/sample - loss: 0.0453 - accuracy: 0.9824 - val_loss: 0.2659 - val_accuracy: 0.9423\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 345s 7ms/sample - loss: 0.0431 - accuracy: 0.9834 - val_loss: 0.2696 - val_accuracy: 0.9438\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 345s 7ms/sample - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.2852 - val_accuracy: 0.9428\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 343s 7ms/sample - loss: 0.0415 - accuracy: 0.9838 - val_loss: 0.2903 - val_accuracy: 0.9427\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 344s 7ms/sample - loss: 0.0400 - accuracy: 0.9846 - val_loss: 0.2749 - val_accuracy: 0.9430\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 342s 7ms/sample - loss: 0.0380 - accuracy: 0.9854 - val_loss: 0.2892 - val_accuracy: 0.9423\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 341s 7ms/sample - loss: 0.0367 - accuracy: 0.9858 - val_loss: 0.2878 - val_accuracy: 0.9432\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 339s 7ms/sample - loss: 0.0346 - accuracy: 0.9867 - val_loss: 0.3034 - val_accuracy: 0.9431\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 343s 7ms/sample - loss: 0.0336 - accuracy: 0.9879 - val_loss: 0.3324 - val_accuracy: 0.9421\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 339s 7ms/sample - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.3060 - val_accuracy: 0.9427\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 343s 7ms/sample - loss: 0.0312 - accuracy: 0.9883 - val_loss: 0.3206 - val_accuracy: 0.9423\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 339s 7ms/sample - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.3274 - val_accuracy: 0.9416\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 342s 7ms/sample - loss: 0.0289 - accuracy: 0.9895 - val_loss: 0.3425 - val_accuracy: 0.9417\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 344s 7ms/sample - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.3154 - val_accuracy: 0.9405\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 553s 12ms/sample - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.3460 - val_accuracy: 0.9419\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 569s 12ms/sample - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.3403 - val_accuracy: 0.9425\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 564s 12ms/sample - loss: 0.0270 - accuracy: 0.9901 - val_loss: 0.3224 - val_accuracy: 0.9433\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 566s 12ms/sample - loss: 0.0260 - accuracy: 0.9904 - val_loss: 0.3361 - val_accuracy: 0.9419\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 565s 12ms/sample - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.3290 - val_accuracy: 0.9429\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 557s 12ms/sample - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.3607 - val_accuracy: 0.9413\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 491s 10ms/sample - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.3531 - val_accuracy: 0.9423\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 433s 9ms/sample - loss: 0.0210 - accuracy: 0.9924 - val_loss: 0.3490 - val_accuracy: 0.9421\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 422s 9ms/sample - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.3659 - val_accuracy: 0.9430\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.0001)\n",
    "earlystop=EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "train_model = model.fit(x_tr, y_tr, batch_size=32, epochs=50, verbose=1, validation_data=(x_vl, y_vl),callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "tracked-voice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.3999 - accuracy: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3998530549506275, 0.941]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-development",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
