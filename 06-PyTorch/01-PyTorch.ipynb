{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radio-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "True\n",
      "GeForce GTX 1050 Ti\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-depression",
   "metadata": {},
   "source": [
    "### Tensor Basics\n",
    "A tensor is a generalization of vectors and matrices and is easily available as a multidimensional array. It is a term and set od techniques known in the machine learning in the trainingand operation of deep learning models can be described in terms of tensors. In many cases are used as a replacement for NumPy to use the power of GPUs.\n",
    "\n",
    "Tensors are a type of data structure used in linear algebra, and like vectors and matrices, can calculate arithmetic operations with tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-elements",
   "metadata": {},
   "source": [
    "#### Covert NumPy array to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "limited-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "tensor([4, 6, 8, 7, 9, 5], dtype=torch.int32)\n",
      "tensor([4, 6], dtype=torch.int32)\n",
      "tensor([6, 8, 7], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "lst = [4,6,8,7,9,5]\n",
    "arr = np.array(lst)\n",
    "print(arr.dtype)\n",
    "\n",
    "tensors=torch.from_numpy(arr)\n",
    "print(tensors)\n",
    "\n",
    "# indexing similar to numpy\n",
    "print(tensors[:2])\n",
    "print(tensors[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premium-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  4,   6,   8, 100,   9,   5], dtype=torch.int32)\n",
      "[  4   6   8 100   9   5]\n"
     ]
    }
   ],
   "source": [
    "# Disadvantage of from_numpy => The array and tensor uses the same memory location\n",
    "tensors[3] = 100\n",
    "print(tensors)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sacred-blast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  4,   6,   8, 500,   9,   5], dtype=torch.int32)\n",
      "[  4   6   8 100   9   5]\n"
     ]
    }
   ],
   "source": [
    "# Prevent this by using torch.tensor\n",
    "tensor_arr = torch.tensor(arr)\n",
    "tensor_arr[3] = 500\n",
    "print(tensor_arr)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-director",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
